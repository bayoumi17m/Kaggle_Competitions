{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:08.333832Z",
     "start_time": "2017-12-27T18:05:58.632647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:08.351316Z",
     "start_time": "2017-12-27T18:06:08.338381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on': 6, 'no': 1, 'up': 2, 'stop': 8, 'off': 7, 'left': 4, 'yes': 0, 'go': 9, 'right': 5, 'down': 3, 'unknown': 11, 'silence': 10}\n"
     ]
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "print(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:08.595308Z",
     "start_time": "2017-12-27T18:06:08.355216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    \n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label, label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    \n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    \n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    \n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:10.342479Z",
     "start_time": "2017-12-27T18:06:08.600066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train and 6798 val samples\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = load_data('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:10.617531Z",
     "start_time": "2017-12-27T18:06:10.345343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wav_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>8eb4a1bf</td>\n",
       "      <td>./data/train/audio/yes/8eb4a1bf_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>9b402bc2</td>\n",
       "      <td>./data/train/audio/yes/9b402bc2_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>20174140</td>\n",
       "      <td>./data/train/audio/yes/20174140_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3b8406c0</td>\n",
       "      <td>./data/train/audio/yes/3b8406c0_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>9c59dd28</td>\n",
       "      <td>./data/train/audio/yes/9c59dd28_nohash_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_id   user_id                                      wav_file\n",
       "0   yes         0  8eb4a1bf  ./data/train/audio/yes/8eb4a1bf_nohash_3.wav\n",
       "1   yes         0  9b402bc2  ./data/train/audio/yes/9b402bc2_nohash_0.wav\n",
       "2   yes         0  20174140  ./data/train/audio/yes/20174140_nohash_0.wav\n",
       "3   yes         0  3b8406c0  ./data/train/audio/yes/3b8406c0_nohash_1.wav\n",
       "4   yes         0  9c59dd28  ./data/train/audio/yes/9c59dd28_nohash_2.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:10.660240Z",
     "start_time": "2017-12-27T18:06:10.619873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    36818\n",
       "stop        2134\n",
       "yes         2116\n",
       "up          2115\n",
       "go          2112\n",
       "right       2111\n",
       "on          2110\n",
       "left        2106\n",
       "no          2105\n",
       "off         2101\n",
       "down        2095\n",
       "silence        6\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:10.837019Z",
     "start_time": "2017-12-27T18:06:10.662712Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separating silence data\n",
    "silence_files = train_df[train_df.label == 'silence']\n",
    "train_df      = train_df[train_df.label != 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:13.559213Z",
     "start_time": "2017-12-27T18:06:10.841647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def read_wav_file(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:13.785661Z",
     "start_time": "2017-12-27T18:06:13.562475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainath/anaconda3/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399.3981875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the silence data\n",
    "silence_data = np.concatenate([read_wav_file(x) for x in silence_files.wav_file.values])\n",
    "len(silence_data)/16000 # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:14.733982Z",
     "start_time": "2017-12-27T18:06:13.788198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "def calc_phase_amp(wav):\n",
    "    specgram = stft(wav, 16000, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "    phase = np.angle(specgram[2]) / np.pi\n",
    "    amp = np.log1p(np.abs(specgram[2]))\n",
    "    return np.concatenate([phase, amp], axis = 1)\n",
    "\n",
    "def process_wav_file(fname):\n",
    "    wav = read_wav_file(fname)\n",
    "    \n",
    "    L = 16000  # 1 sec\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L) # if length is more than 1s, randomly sample the file\n",
    "        wav = wav[i:(i+L)]\n",
    "    elif len(wav) < L: # if length is less than 1s, add silence on both ends to make it 1s\n",
    "        rem_len = L - len(wav)\n",
    "        i = np.random.randint(0, len(silence_data) - rem_len)\n",
    "        silence_part = silence_data[i:(i+L)]\n",
    "        j = np.random.randint(0, rem_len)\n",
    "        silence_part_left  = silence_part[0:j]\n",
    "        silence_part_right = silence_part[j:rem_len]\n",
    "        wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "    \n",
    "    return calc_phase_amp(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:22.576535Z",
     "start_time": "2017-12-27T18:06:14.736807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:22.643105Z",
     "start_time": "2017-12-27T18:06:22.580740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_train = train_df.copy()\n",
    "        \n",
    "        # let's say we have about 400 silence files (since we have ~400s of silence data)\n",
    "        ids = list(range(this_train.shape[0]))\n",
    "        ids = ids + [None]*400\n",
    "        \n",
    "        shuffled_ids = random.sample(ids, len(ids))\n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            \n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            \n",
    "            for i in i_train_batch:\n",
    "                if i is None:\n",
    "                    k = np.random.randint(0, len(silence_data) - 16000)\n",
    "                    this_silence = silence_data[k:(k+16000)]\n",
    "                    x_batch.append(calc_phase_amp(this_silence))\n",
    "                    y_batch.append(name2id['silence'])\n",
    "                else:\n",
    "                    x_batch.append(process_wav_file(this_train.wav_file.values[i]))\n",
    "                    y_batch.append(this_train.label_id.values[i])\n",
    "            \n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:22.810403Z",
     "start_time": "2017-12-27T18:06:22.646505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(process_wav_file(valid_df.wav_file.values[i]))\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:22.892597Z",
     "start_time": "2017-12-27T18:06:22.813927Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import LSTM, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.346426Z",
     "start_time": "2017-12-27T18:06:22.896267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_in = Input(shape = (257,196))\n",
    "x = BatchNormalization()(x_in)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax')(x)\n",
    "model = Model(inputs = x_in, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.364618Z",
     "start_time": "2017-12-27T18:06:24.349209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 257, 196)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 257, 196)          784       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 256)         463872    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,075,036\n",
      "Trainable params: 2,074,644\n",
      "Non-trainable params: 392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.446327Z",
     "start_time": "2017-12-27T18:06:24.367050Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.513822Z",
     "start_time": "2017-12-27T18:06:24.450750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=4,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.01,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=2,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                               mode='min'),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/03-weights.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.579805Z",
     "start_time": "2017-12-27T18:06:24.518191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455.6484375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df.shape[0] + 400) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.669699Z",
     "start_time": "2017-12-27T18:06:24.583299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.109375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_df.shape[0])/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T18:06:24.789569Z",
     "start_time": "2017-12-27T18:06:24.673685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T23:55:06.574246Z",
     "start_time": "2017-12-27T18:06:24.791897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "993s - loss: 1.5750 - categorical_accuracy: 0.6300 - val_loss: 1.5534 - val_categorical_accuracy: 0.6192\n",
      "Epoch 2/25\n",
      "933s - loss: 1.5295 - categorical_accuracy: 0.6334 - val_loss: 1.5357 - val_categorical_accuracy: 0.6200\n",
      "Epoch 3/25\n",
      "923s - loss: 1.5277 - categorical_accuracy: 0.6333 - val_loss: 1.5398 - val_categorical_accuracy: 0.6205\n",
      "Epoch 4/25\n",
      "824s - loss: 1.5236 - categorical_accuracy: 0.6332 - val_loss: 1.5316 - val_categorical_accuracy: 0.6209\n",
      "Epoch 5/25\n",
      "823s - loss: 1.5117 - categorical_accuracy: 0.6328 - val_loss: 1.5035 - val_categorical_accuracy: 0.6209\n",
      "Epoch 6/25\n",
      "822s - loss: 1.4790 - categorical_accuracy: 0.6326 - val_loss: 1.4578 - val_categorical_accuracy: 0.6209\n",
      "Epoch 7/25\n",
      "823s - loss: 1.4205 - categorical_accuracy: 0.6343 - val_loss: 1.4234 - val_categorical_accuracy: 0.6208\n",
      "Epoch 8/25\n",
      "822s - loss: 1.3752 - categorical_accuracy: 0.6348 - val_loss: 1.3284 - val_categorical_accuracy: 0.6224\n",
      "Epoch 9/25\n",
      "821s - loss: 1.3081 - categorical_accuracy: 0.6374 - val_loss: 1.2799 - val_categorical_accuracy: 0.6262\n",
      "Epoch 10/25\n",
      "820s - loss: 1.2427 - categorical_accuracy: 0.6413 - val_loss: 1.2157 - val_categorical_accuracy: 0.6333\n",
      "Epoch 11/25\n",
      "820s - loss: 1.1501 - categorical_accuracy: 0.6548 - val_loss: 1.1471 - val_categorical_accuracy: 0.6489\n",
      "Epoch 12/25\n",
      "820s - loss: 1.0596 - categorical_accuracy: 0.6737 - val_loss: 1.0901 - val_categorical_accuracy: 0.6625\n",
      "Epoch 13/25\n",
      "820s - loss: 0.9692 - categorical_accuracy: 0.6959 - val_loss: 1.0285 - val_categorical_accuracy: 0.6783\n",
      "Epoch 14/25\n",
      "820s - loss: 0.8743 - categorical_accuracy: 0.7204 - val_loss: 0.9025 - val_categorical_accuracy: 0.7195\n",
      "Epoch 15/25\n",
      "820s - loss: 0.7682 - categorical_accuracy: 0.7544 - val_loss: 0.8980 - val_categorical_accuracy: 0.7267\n",
      "Epoch 16/25\n",
      "819s - loss: 0.6544 - categorical_accuracy: 0.7908 - val_loss: 0.7489 - val_categorical_accuracy: 0.7763\n",
      "Epoch 17/25\n",
      "821s - loss: 0.5722 - categorical_accuracy: 0.8196 - val_loss: 0.7009 - val_categorical_accuracy: 0.7854\n",
      "Epoch 18/25\n",
      "820s - loss: 0.5533 - categorical_accuracy: 0.8304 - val_loss: 0.7559 - val_categorical_accuracy: 0.7973\n",
      "Epoch 19/25\n",
      "820s - loss: 0.4716 - categorical_accuracy: 0.8522 - val_loss: 0.6662 - val_categorical_accuracy: 0.8058\n",
      "Epoch 20/25\n",
      "820s - loss: 0.4238 - categorical_accuracy: 0.8690 - val_loss: 0.6883 - val_categorical_accuracy: 0.8046\n",
      "Epoch 21/25\n",
      "820s - loss: 0.3927 - categorical_accuracy: 0.8797 - val_loss: 0.6883 - val_categorical_accuracy: 0.8083\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00021: reducing learning rate to 0.00010000000474974513.\n",
      "819s - loss: 0.3467 - categorical_accuracy: 0.8939 - val_loss: 0.6822 - val_categorical_accuracy: 0.8216\n",
      "Epoch 23/25\n",
      "822s - loss: 0.2283 - categorical_accuracy: 0.9318 - val_loss: 0.6433 - val_categorical_accuracy: 0.8414\n",
      "Epoch 24/25\n",
      "821s - loss: 0.1940 - categorical_accuracy: 0.9420 - val_loss: 0.6579 - val_categorical_accuracy: 0.8448\n",
      "Epoch 25/25\n",
      "821s - loss: 0.1717 - categorical_accuracy: 0.9488 - val_loss: 0.7276 - val_categorical_accuracy: 0.8455\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator(128),\n",
    "                              steps_per_epoch=456,\n",
    "                              epochs=25,\n",
    "                              verbose=2,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(128),\n",
    "                              validation_steps=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
