{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on tensorflow starter code from https://www.kaggle.com/alexozerin/end-to-end-baseline-tf-estimator-lb-0-72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:18.349702Z",
     "start_time": "2017-12-27T11:23:17.187864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:18.782486Z",
     "start_time": "2017-12-27T11:23:18.772191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 0, 'down': 3, 'silence': 10, 'left': 4, 'right': 5, 'stop': 8, 'no': 1, 'up': 2, 'unknown': 11, 'go': 9, 'on': 6, 'off': 7}\n"
     ]
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "print(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:20.059593Z",
     "start_time": "2017-12-27T11:23:19.931603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    \n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label, label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    \n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    \n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    \n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:22.042900Z",
     "start_time": "2017-12-27T11:23:21.053103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train and 6798 val samples\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = load_data('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:22.072223Z",
     "start_time": "2017-12-27T11:23:22.045133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wav_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>8eb4a1bf</td>\n",
       "      <td>./data/train/audio/yes/8eb4a1bf_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>9b402bc2</td>\n",
       "      <td>./data/train/audio/yes/9b402bc2_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>20174140</td>\n",
       "      <td>./data/train/audio/yes/20174140_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3b8406c0</td>\n",
       "      <td>./data/train/audio/yes/3b8406c0_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>9c59dd28</td>\n",
       "      <td>./data/train/audio/yes/9c59dd28_nohash_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_id   user_id                                      wav_file\n",
       "0   yes         0  8eb4a1bf  ./data/train/audio/yes/8eb4a1bf_nohash_3.wav\n",
       "1   yes         0  9b402bc2  ./data/train/audio/yes/9b402bc2_nohash_0.wav\n",
       "2   yes         0  20174140  ./data/train/audio/yes/20174140_nohash_0.wav\n",
       "3   yes         0  3b8406c0  ./data/train/audio/yes/3b8406c0_nohash_1.wav\n",
       "4   yes         0  9c59dd28  ./data/train/audio/yes/9c59dd28_nohash_2.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:23.917705Z",
     "start_time": "2017-12-27T11:23:23.895549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    36818\n",
       "stop        2134\n",
       "yes         2116\n",
       "up          2115\n",
       "go          2112\n",
       "right       2111\n",
       "on          2110\n",
       "left        2106\n",
       "no          2105\n",
       "off         2101\n",
       "down        2095\n",
       "silence        6\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:26.118770Z",
     "start_time": "2017-12-27T11:23:26.021942Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separating silence data\n",
    "silence_files = train_df[train_df.label == 'silence']\n",
    "train_df      = train_df[train_df.label != 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:30.719288Z",
     "start_time": "2017-12-27T11:23:29.811673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def read_wav_file(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:31.645111Z",
     "start_time": "2017-12-27T11:23:31.547616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainath/anaconda3/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399.3981875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the silence data\n",
    "silence_data = np.concatenate([read_wav_file(x) for x in silence_files.wav_file.values])\n",
    "len(silence_data)/16000 # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:34.007484Z",
     "start_time": "2017-12-27T11:23:33.212462Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "def calc_phase_amp(wav):\n",
    "    specgram = stft(wav, 16000, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "    phase = np.angle(specgram[2]) / np.pi\n",
    "    amp = np.log1p(np.abs(specgram[2]))\n",
    "    return np.stack([phase, amp], axis = 2)\n",
    "\n",
    "def process_wav_file(fname):\n",
    "    wav = read_wav_file(fname)\n",
    "    \n",
    "    L = 16000  # 1 sec\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L) # if length is more than 1s, randomly sample the file\n",
    "        wav = wav[i:(i+L)]\n",
    "    elif len(wav) < L: # if length is less than 1s, add silence on both ends to make it 1s\n",
    "        rem_len = L - len(wav)\n",
    "        i = np.random.randint(0, len(silence_data) - rem_len)\n",
    "        silence_part = silence_data[i:(i+L)]\n",
    "        j = np.random.randint(0, rem_len)\n",
    "        silence_part_left  = silence_part[0:j]\n",
    "        silence_part_right = silence_part[j:rem_len]\n",
    "        wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "    \n",
    "    return calc_phase_amp(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:39.778540Z",
     "start_time": "2017-12-27T11:23:35.262713Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:53.864952Z",
     "start_time": "2017-12-27T11:23:53.782251Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_train = train_df.copy()\n",
    "        \n",
    "        # let's say we have about 400 silence files (since we have ~400s of silence data)\n",
    "        ids = list(range(this_train.shape[0]))\n",
    "        ids = ids + [None]*400\n",
    "        \n",
    "        shuffled_ids = random.sample(ids, len(ids))\n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            \n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            \n",
    "            for i in i_train_batch:\n",
    "                if i is None:\n",
    "                    k = np.random.randint(0, len(silence_data) - 16000)\n",
    "                    this_silence = silence_data[k:(k+16000)]\n",
    "                    x_batch.append(calc_phase_amp(this_silence))\n",
    "                    y_batch.append(name2id['silence'])\n",
    "                else:\n",
    "                    x_batch.append(process_wav_file(this_train.wav_file.values[i]))\n",
    "                    y_batch.append(this_train.label_id.values[i])\n",
    "            \n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:56.203916Z",
     "start_time": "2017-12-27T11:23:56.171676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(process_wav_file(valid_df.wav_file.values[i]))\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:23:59.837279Z",
     "start_time": "2017-12-27T11:23:59.301939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 257, 98, 2)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 257, 98, 2)    8           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 255, 96, 16)   304         batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 255, 96, 16)   0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 255, 96, 16)   64          activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 127, 48, 16)   0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 125, 46, 32)   4640        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 125, 46, 32)   0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 125, 46, 32)   128         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 62, 23, 32)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 60, 21, 64)    18496       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 60, 21, 64)    0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 60, 21, 64)    256         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 30, 10, 64)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 28, 8, 128)    73856       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 28, 8, 128)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 28, 8, 128)    512         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 14, 4, 128)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 14, 4, 128)    16512       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 128)           0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalMa (None, 128)           0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           global_average_pooling2d_1[0][0] \n",
      "                                                                   global_max_pooling2d_1[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 12)            1548        dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 149,220\n",
      "Trainable params: 148,736\n",
      "Non-trainable params: 484\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_in = Input(shape = (257,98,2))\n",
    "x = BatchNormalization()(x_in)\n",
    "for i in range(4):\n",
    "    x = Conv2D(16*(2 ** i), (3,3))(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "x = Conv2D(128, (1,1))(x)\n",
    "x_branch_1 = GlobalAveragePooling2D()(x)\n",
    "x_branch_2 = GlobalMaxPool2D()(x)\n",
    "x = concatenate([x_branch_1, x_branch_2])\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax')(x)\n",
    "model = Model(inputs = x_in, outputs = x)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:24:01.955929Z",
     "start_time": "2017-12-27T11:24:01.949985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:24:03.699000Z",
     "start_time": "2017-12-27T11:24:03.684447Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=4,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.01,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=2,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                               mode='min'),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/02-weights.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:24:12.584506Z",
     "start_time": "2017-12-27T11:24:12.576247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455.6484375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df.shape[0] + 400) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T11:24:13.403072Z",
     "start_time": "2017-12-27T11:24:13.392916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.109375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_df.shape[0])/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T12:24:55.482247Z",
     "start_time": "2017-12-27T11:24:23.300305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "273s - loss: 1.4869 - categorical_accuracy: 0.6320 - val_loss: 4.0851 - val_categorical_accuracy: 0.1403\n",
      "Epoch 2/25\n",
      "258s - loss: 0.8002 - categorical_accuracy: 0.7457 - val_loss: 0.5796 - val_categorical_accuracy: 0.8071\n",
      "Epoch 3/25\n",
      "257s - loss: 0.4991 - categorical_accuracy: 0.8413 - val_loss: 0.5486 - val_categorical_accuracy: 0.8441\n",
      "Epoch 4/25\n",
      "259s - loss: 0.3825 - categorical_accuracy: 0.8817 - val_loss: 0.4293 - val_categorical_accuracy: 0.8754\n",
      "Epoch 5/25\n",
      "255s - loss: 0.3194 - categorical_accuracy: 0.9016 - val_loss: 0.2933 - val_categorical_accuracy: 0.9134\n",
      "Epoch 6/25\n",
      "263s - loss: 0.2776 - categorical_accuracy: 0.9147 - val_loss: 0.5409 - val_categorical_accuracy: 0.8704\n",
      "Epoch 7/25\n",
      "249s - loss: 0.2487 - categorical_accuracy: 0.9251 - val_loss: 0.4256 - val_categorical_accuracy: 0.9011\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00007: reducing learning rate to 0.00010000000474974513.\n",
      "257s - loss: 0.2307 - categorical_accuracy: 0.9304 - val_loss: 0.4185 - val_categorical_accuracy: 0.9026\n",
      "Epoch 9/25\n",
      "250s - loss: 0.1467 - categorical_accuracy: 0.9559 - val_loss: 0.2459 - val_categorical_accuracy: 0.9381\n",
      "Epoch 10/25\n",
      "258s - loss: 0.1235 - categorical_accuracy: 0.9634 - val_loss: 0.2499 - val_categorical_accuracy: 0.9413\n",
      "Epoch 11/25\n",
      "259s - loss: 0.1159 - categorical_accuracy: 0.9658 - val_loss: 0.2485 - val_categorical_accuracy: 0.9381\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00011: reducing learning rate to 1.0000000474974514e-05.\n",
      "264s - loss: 0.1059 - categorical_accuracy: 0.9684 - val_loss: 0.2660 - val_categorical_accuracy: 0.9379\n",
      "Epoch 13/25\n",
      "258s - loss: 0.0977 - categorical_accuracy: 0.9703 - val_loss: 0.2596 - val_categorical_accuracy: 0.9406\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00013: reducing learning rate to 1.0000000656873453e-06.\n",
      "264s - loss: 0.0978 - categorical_accuracy: 0.9707 - val_loss: 0.2601 - val_categorical_accuracy: 0.9397\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator(128),\n",
    "                              steps_per_epoch=456,\n",
    "                              epochs=25,\n",
    "                              verbose=2,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(128),\n",
    "                              validation_steps=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T12:25:31.364113Z",
     "start_time": "2017-12-27T12:25:31.222792Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/02-weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T12:25:33.633098Z",
     "start_time": "2017-12-27T12:25:32.791099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T12:25:34.824905Z",
     "start_time": "2017-12-27T12:25:34.806252Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(test_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(test_paths), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(test_paths))\n",
    "            this_paths = test_paths[start:end]\n",
    "            for x in this_paths:\n",
    "                x_batch.append(process_wav_file(x))\n",
    "            x_batch = np.array(x_batch)\n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T13:01:29.848248Z",
     "start_time": "2017-12-27T12:25:37.192318Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator(256), int(np.ceil(len(test_paths)/256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T13:01:29.861749Z",
     "start_time": "2017-12-27T13:01:29.850802Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T13:01:30.519670Z",
     "start_time": "2017-12-27T13:01:29.864154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T13:01:30.727613Z",
     "start_time": "2017-12-27T13:01:30.522440Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission2.csv', 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T13:01:30.985989Z",
     "start_time": "2017-12-27T13:01:30.729571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    98727\n",
       "silence     7288\n",
       "off         6410\n",
       "no          5912\n",
       "left        5552\n",
       "yes         5436\n",
       "stop        5041\n",
       "on          5006\n",
       "up          4814\n",
       "down        4799\n",
       "right       4793\n",
       "go          4760\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(key, submission[key]) for key in submission], columns=['file', 'label']).label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "none",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
